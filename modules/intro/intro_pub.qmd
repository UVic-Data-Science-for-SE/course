---
title: "Introduction to Data Science for/in/about SE"
author: "Neil Ernst"
date: last-modified
---

# Intro

nernst@uvic.ca 
ECS 560

## Syllabus 

Updates? New topics?

Project in 6 weeks. Plan accordingly!

# Exercise: Icebreaker {.exercise}

# Overview

# Short Break {.break}

# Data Science 
## Analytical techniques can include:

* Descriptive stats like mean/median, variance, histograms, scatterplots
* Inferential stats like Bayesian inference, maximum likelihood, hypothesis testing
* Unsupervised clustering  of data
* Predicting future values of data
* Finding a function that successfully captures the generative model e.g. with a neural network

# Software Data

Like many areas, software development produces tons of data:

* **Productivity** stats like lines of code per hour;
* **Communication** patterns like developer code review histories;
* **Natural language text **like issues and bug report dicussions
* **Code** and code changes;
* Tool logs like build logs;
* Application specific metrics, such as uptime or fault reports.
* many others

##  Data Types
* Quantitative
  * Nominal
  * Ordinal
  * Interval/Ratio
* Symbolic
* Qualitative 

##
![](https://raw.githubusercontent.com/txt/ase19/master/etc/img/dots1.png)

##

![width:500](https://raw.githubusercontent.com/txt/ase19/master/etc/img/dots2.png)

##

![width:1000px](https://raw.githubusercontent.com/txt/ase19/master/etc/img/cellphone.png) 

##

![](https://raw.githubusercontent.com/txt/ase19/master/etc/img/translatefm.png)

(Source: [Menzies](https://github.com/txt/ase19/blob/master/docs/overview.md#top))

## Nine step AI pipeline

![](https://github.com/txt/ase19/blob/master/etc/img/9steps.png?raw=true)

## six steps of statistical modeling

1. specification (create a model)
2. [identification]([url](https://en.wikipedia.org/wiki/Identifiability)) (check if, given a new parameterization, your model's predictions change)
3. estimation (use the model to produce estimates)
4. evaluation (check the model; does the estimate match reality)
5. respecification (redo the model or try other models)
6. interpretation 

# Model comparison and exploratory data analysis

##
When presented with data or a theory about how data is created, what should we do?

* Explore the data with few preconceptions
  * look for the patterns
* Problem: this might bias us if the patterns are just noise

##

* Explore vs. confirm
  * Confirm: verify data support/reject hypothesis
* Hard to draw a line (Hullman and Gelman, 2021)
* Better intuition: explore means comparing data (typically visually) to a pseudo-statistical model (our prior).
* Then, create a more rigorous statistical model and compare alternatives.

## Types of tools

* **Data miners**, that tell us what is in the data and build a model: nearest neighbors, decision trees, deep learners
* **Optimizers**, that tell us what to do, specifically, how to do something simple that has the biggest positive impact: genetic algorithms, heuristic search, etc.


# TPS exercise {.exercise}

*think* about the following question: "You are the software engineering manager or team lead at a big company. What is one key question you want to know the answer to for effectively running your team". 

Write down a quick answer you have - maybe from your past experience. 

Then *pair* with your table partner to *share* and discuss their answer and yours. We will then collect a few responses from the class as a whole. 


# Ethics Implications

- how did we get the data? was there consent?
- what is missing? 
- what assumptions are bing made in the model? 
- whose views are not included?
- (more to come later in term)

# Cross Tool Logs example

1. How to read the papers
1. Methods used
2. Types of Constructs
3. Belief in Results - Practical Significance

# Longish Break {.break}

# Setting Up R, RStudio, AI tooling

We will now spend some time getting the basic tooling for this class installed. 

::: {.notes}
1. open terminal and 
2. open RStudio. Go over basics of RStudio.
3. Wait. Allow them to do this. 
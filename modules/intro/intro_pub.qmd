---
title: "Introduction to Data Science for/in/about SE"
author: "Neil Ernst"
date: last-modified
---

# Intro

nernst@uvic.ca 
ECS 560

## Syllabus 

Updates? New topics?

Project in 6 weeks. Plan accordingly!

## AI - General Philosophy

>What’s the essential skill that students need to be learning, such that when they get out of school they are more capable humans than when they went in?

> the answer ... isn’t simply a body of knowledge to be memorized or a set of skills to be mastered. It’s a stance. A stance from which to address the world and all its challenges. A stance built on self-confidence and resilience: the conviction that one has a fighting chance to overcome or circumvent whatever obstacles the world throws in one’s path. **The way you acquire it is by trying, and sometimes failing, to do difficult things.** It can be discouraging, but if you have good mentors, and if you’re collaborating with friends who are in the same boat, you can find ways to succeed, and develop a knack for it. That’s true self-reliance.

-- Neal Stephenson [via newsletter](https://substack.com/app-link/post?publication_id=2694786&post_id=166816228]

# Exercise: Icebreaker {.exercise}

# Overview

<div style='position: relative; padding-bottom: 56.25%; padding-top: 35px; height: 0; overflow: hidden;'><iframe sandbox='allow-scripts allow-same-origin allow-presentation' allowfullscreen='true' allowtransparency='true' frameborder='0' height='315' src='https://www.mentimeter.com/app/presentation/alfcrmis7rrgrk77617qq7xkvbtiu251/embed' style='position: absolute; top: 0; left: 0; width: 100%; height: 100%;' width='420'></iframe></div>


# Short Break {.break}

# Data Science 
## Analytical techniques can include:

* Descriptive stats like mean/median, variance, histograms, scatterplots
* Inferential stats like Bayesian inference, maximum likelihood, hypothesis testing
* Unsupervised clustering  of data
* Predicting future values of data
* Finding a function that successfully captures the generative model e.g. with a neural network

# Software Data

Like many areas, software development produces tons of data:

* **Productivity** stats like lines of code per hour;
* **Communication** patterns like developer code review histories;
* **Natural language text **like issues and bug report dicussions
* **Code** and code changes;
* Tool logs like build logs;
* Application specific metrics, such as uptime or fault reports.
* many others

##  Data Types
* Quantitative
  * Nominal
  * Ordinal
  * Interval/Ratio
* Symbolic
* Qualitative 

##
![](https://raw.githubusercontent.com/txt/ase19/master/etc/img/dots1.png)

##

![width:500](https://raw.githubusercontent.com/txt/ase19/master/etc/img/dots2.png)

##

![width:1000px](https://raw.githubusercontent.com/txt/ase19/master/etc/img/cellphone.png) 

##

![](https://raw.githubusercontent.com/txt/ase19/master/etc/img/translatefm.png)

(Source: [Menzies](https://github.com/txt/ase19/blob/master/docs/overview.md#top))

## Nine step AI pipeline

![](https://github.com/txt/ase19/blob/master/etc/img/9steps.png?raw=true)

## six steps of statistical modeling

1. specification (create a model)
2. [identification]([url](https://en.wikipedia.org/wiki/Identifiability)) (check if, given a new parameterization, your model's predictions change)
3. estimation (use the model to produce estimates)
4. evaluation (check the model; does the estimate match reality)
5. respecification (redo the model or try other models)
6. interpretation 

# Model comparison and exploratory data analysis

##
When presented with data or a theory about how data is created, what should we do?

* Explore the data with few preconceptions
  * look for the patterns
* Problem: this might bias us if the patterns are just noise

##

* **Explore** vs. **confirm**
  * Confirm: verify data support/reject hypothesis
* Hard to draw a line (Hullman and Gelman, 2021)
* Better intuition: **explore** means comparing data (typically visually) to a pseudo-statistical model (our prior).
* Only then do we create a more rigorous statistical model and compare alternatives.

## Types of tools

* **Data miners**, that tell us what is in the data and build a model: nearest neighbors, decision trees, deep learners
* **Optimizers**, that tell us what to do, specifically, how to do something simple that has the biggest positive impact: genetic algorithms, heuristic search, etc.


# Exercise: TPS on team metrics {.exercise}

Visit SonarCloud.io and explore the data science dashboard there.

* Q. what is the part of the code that needs attention? How do you know this? 
* Q. what do you make of "issues"? Where do you start with a remediation project?  

![sonar cloud qr code](../images/sonarcloud-mw-qr.png)

{.notes}
Since we can tweak data and analysis approaches in a variety of ways, one question we should think seriously about is ethical implications. People tend to ascribe a lot of weight to a data analysis, and ignore the many assumptions that underpin that analysis (e.g., how did we get the data in the first place? What was *Not* captured?)

Some ethical dimensions include privacy, regulatory compliance and safety, diversity and inclusion, etc. ...

Consider the two examples of advanced AI for code completion I attached to the readings, Github Copilot and OpenAI's Codex (both derived from GPT3). What are some possible issues with these tools? 
:::

# Cross Tool Logs example

1. How to read the papers
1. Methods used
2. Types of Constructs
3. Belief in Results - Practical Significance

# Longish Break {.break}

# Activity: Setting Up R, RStudio, AI tooling

We will now spend some time getting the basic tooling for this class installed. 


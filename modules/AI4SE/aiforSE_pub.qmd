---
title: "Effectively using AI in SE"
author: "Neil Ernst"
format: 
  revealjs:
    theme: default
    slide-number: true
    logo: img/ENGN_vert_bk.jpg
    footer: "Neil Ernst (c)"
date: last-modified
---

## Caveats
- I am learning as I go, as you are.
- Things have moved fast, and there are many tools to choose from.
- More effective models tend to cost more. 
- I don't think AI will replace thinking.

## Vibe Coding {.exercise}

![](../images/F633DAA1-BDAB-4D44-A629-350A9617DDB0.png)

## GenAI and Programming and Data Science
In what ways is GenAI transforming this field? What should we do in this class in response? 

## Policies

See the [course README file](https://github.com/UVic-Data-Science-For-SE/).

## How to Use AI as a Student
(from https://substack.com/home/post/p-160131730)

Emphasize craftsmanship. AI rewards having a structured, careful development process:

1. Thinking hard and chatting about the problem and the changes you need to implement before doing anything
2. Keeping components encapsulated with carefully-designed interfaces
3. Controlling the scope of your changes; current AIs work best at the function or class level
4. Testing and validation; how do you know your program works
5. Good manual debugging skills (this was a major takeaway from the class - students found AI debugging to be unreliable)
6. General system knowledge: networking, OS, data formats, databases

## Shopify's approach

![](../images/shopify-AI.jpeg)

## Useful guides for using LLMs
* https://rtl.chrisadams.me.uk/2024/12/how-i-use-llms-neat-tricks-with-simons-llm-tool/
* all and any of Simon Willison's writing

## Accessible tools (financially)
* [Claude student version](https://www.anthropic.com/contact-sales/for-student-builders)
* [Copilot for students](https://education.github.com/pack)

# Exercise: Use LLMs {.exercise}

## Exercise: Use LLMs {background-color="aquamarine"}
We will do what Andrej Karpathy calls "vibe coding": a zen-like use of autocomplete to try and get the AI to do something useful. Kent Beck has this nice image of how this works.

1. Download this data file: https://github.com/datasciencedojo/datasets/blob/master/titanic.csv
2. Setup an AI tool. I am showing `aider`. 
3. Get the AI to parse the data file and show simple descriptive stats in R notebook. 
4. Display the graph. 

<!-- there is something more than 'vibe coding' which is interactive and iterative development, wandering a path but with some goal in mind -->

## Building Good Prompts
As Simon Willison [writes](https://simonwillison.net/2025/May/21/chatgpt-new-memory/), 

> The entire game when it comes to prompting LLMs is to carefully control their context-the inputs (and subsequent outputs) that make it into the current conversation with the model.

So how can we do that? 

## Adding Context With RAG
A lot of the challenge with software engineering is understanding what the current program is supposed to be doing---what Peter Naur [called the "theory" of the program](https://pages.cs.wisc.edu/~remzi/Naur.pdf).

The LLM is no different. We need to tell it what to do. 

## Creating Effective Evals
An `eval` is a test that the AI's output is doing what you had hoped. It isn't a `unit test` exactly, since unit tests are repeatable and deterministic (ideally). But an eval should give you a sense that the output is what you expect. 

What is an eval for a data analysis project? 

- how many NaNs?
- what is the expected mean/median for the data, and is it within range? 

### 
This is an emerging space. One approach is [described here](https://simonwillison.net/2025/Apr/24/exploring-promptfoo/). It uses the [PromptFoo](https://www.promptfoo.dev/docs/installation/) tool to manage the workflow.  

### 

The idea is that you prompt the LLM to do something (e.g., generate code), it returns a result, and then the eval is used to examine if the LLM did the right thing. If not, you a) change the model b) add context via RAG or MCP c) redo the prompt. 

Key to eval is the assertion for what the model should look for. In `PromptFoo` there are several [types of assertions](https://www.promptfoo.dev/docs/configuration/expected-outputs/) ^[assert]

^[assert]: They call them assertions, but that's because it's the term used in testing. In this case, the eval is really not going to force any failures, and you might need to interpret the answer in any case. 

### "Assertions"
1. Deterministic 
   1. contains
   2. equals
   3. perplexity
   4. levinshtein
   5. regex
   6. ...
2. Model-graded (we use another LLM to judge)
   1. llm-rubric
   2. select-best
   3. ...

The model-graded assertions take a prompt to the LLM that will judge the output. E.g., `select-best` might say "choose the most concise and accurate response". Now, whether the other LLM will do that is subject to that LLM's performance (you can see the recursion here).

### 
A `.yaml` file holds all the evals for a given problem. [This Google sheet](https://docs.google.com/spreadsheets/d/1-0zlX-80w7edpOlZWUPvTkp28J4HS_ZyKnuDjDtKeoc/edit?gid=0#gid=0) gives some examples for an application that tries to parse government websites for food assistance. 

For example, 
`capability: It gives accurate advice about asset limits based on your state`
`question: I am trying to figure out if I can get food stamps. I lost my job 2 months ago, so have not had any income. But I do have $10,000 in my bank account. I live in Texas. Can I be eligible for food stamps? Answer with only one of: YES, NO, REFUSE.`
`__expected: contains:NO`


## Eval Exercise {background-color="cyan"}

> Install and Configure PromptFoo. 
> Select your preferred AI tool. 
> We are creating a system tht will use an LLM to give us updated information on how to use MongoDB. 
> Create 2 capabilities the LLM should give users, two prompts users might ask, and the PromptFoo validation criteria using assertions.
>
> Then run this example. 

What do you need to develop these evals?

- domain expertise: it helps to know the correct answer. In the sample, that means comprehensive knowledge about food stamps, US federal and state laws and regulations, acronyms, legal cases, etc.
- sense for how often things might change
- cleverness at writing prompts and assertions. This is an art, not a science. 
- $$ to run against different models!

## Other topics to discuss

* Agentic Programming 
* [Model Context Protocol](https://jonturow.substack.com/p/what-mcps-rise-really-shows-a-tale) 
* What becomes of SWE, SDET, Principal SE roles? 
